{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: CudaVision\n",
    "------\n",
    "\n",
    "### Group Members:\n",
    "__1.__ Saikat Roy\n",
    "\n",
    "__2.__ Albert Gubaidullin\n",
    "\n",
    "## Basic Imports\n",
    "------\n",
    "Please note that `torchvision` is only used for the data loading. __`Autograd`__ has __not__ been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pickle\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression object\n",
    "------\n",
    "The `SoftmaxRegression` class is self-contained and contained methods for fitting and predicting based on softmax regression (classification simply by doing 'argmax' of output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression:\n",
    "\n",
    "    def __init__(self, k, n_class):\n",
    "        \"\"\"\n",
    "        Constructor for object initialization\n",
    "\n",
    "        :param k: number of dimensions of the data\n",
    "        :param n_class: number of classes/output variables for the problem\n",
    "        \"\"\"\n",
    "        self.n_class = n_class\n",
    "        self.W = np.random.rand(k, n_class)\n",
    "        self.W = np.append(self.W, np.zeros((1, n_class)),0)\n",
    "\n",
    "    def softmax(self, x, eps=0.0001):\n",
    "        \"\"\"\n",
    "        Softmax Nonlinearity applied to x and returned. Does not do argmax\n",
    "        :param x: 1 x k ndarray\n",
    "        :return: softmax non-linearity applied to x\n",
    "        \"\"\"\n",
    "        return np.exp(x) / (np.sum(np.exp(x))+eps)\n",
    "\n",
    "    def fit(self, x, y, batch_size = 20, lr = 0.01, iters = 100):\n",
    "        \"\"\"\n",
    "        Fit the softmax regression model to data. Final usage as classification or regression model irrelevant here.\n",
    "\n",
    "        :param batch_size: batch size\n",
    "        :param lr: learning rate\n",
    "        :param x: n x k ndarray of data points for model training/fitting\n",
    "        :param y: n x n_class ndarray of labels for fitting\n",
    "        \"\"\"\n",
    "        preds = self.predict(train_x, False)\n",
    "        print(\"Initial Accuracy = {}\".format(calculate_acc(train_y, preds)))\n",
    "\n",
    "        x = np.append(x, np.ones((x.shape[0],1)), 1)\n",
    "        assert x.shape[0] == y.shape[0] # x and y should have same number of samples\n",
    "\n",
    "        # Number of iterations\n",
    "        for iter in range(iters):\n",
    "            for i in range(0, max(1,x.shape[0]-batch_size)): # Iterate over training data\n",
    "\n",
    "                # Make batches\n",
    "                x_batch = x[i:min(i+batch_size,x.shape[0])]\n",
    "                y_batch = y[i:min(i+batch_size,x.shape[0])]\n",
    "\n",
    "                # Get prediction for batch\n",
    "                y_hat_batch = self.predict(x_batch, probs=True, aug1=False)\n",
    "\n",
    "                W_update = np.zeros_like(self.W)\n",
    "\n",
    "                # Iterate over batch\n",
    "                for j in range(batch_size):\n",
    "                    # print(y_hat_batch.shape, y_batch.shape)\n",
    "                    der_t1 = (y_batch[j] - y_hat_batch[j]) * y_hat_batch[j] * (1 - y_hat_batch[j])\n",
    "                    # print(der_t1)\n",
    "                    #exit()\n",
    "                    f = lambda x: x*der_t1\n",
    "                    # print(der_t1.shape, x_batch[j].shape)\n",
    "\n",
    "                    x_rep = np.matlib.repmat(x_batch[j], self.n_class,1)\n",
    "                    # print(x_rep.shape)\n",
    "                    der_t2 = np.apply_along_axis(f, 0, x_rep)\n",
    "                    # print(der_t2.shape)\n",
    "\n",
    "                    # print(W_update.shape)\n",
    "                    W_update = W_update + ((1/batch_size) * der_t2).T\n",
    "\n",
    "                self.W = self.W + lr * W_update\n",
    "                # print(self.W)\n",
    "            preds = self.predict(train_x, False)\n",
    "            print(\"Accuracy after Iteration {} = {}\".format(iter+1, calculate_acc(train_y, preds)))\n",
    "\n",
    "    def predict(self, x, probs = False, aug1 = True):\n",
    "        \"\"\"\n",
    "        Predicts the softmax regression output as classification or regression outputs\n",
    "\n",
    "        :param X: n x k ndarray for prediction\n",
    "        :param probs: True to return probs\n",
    "        :param aug1: True to augment a column of 1s for bias\n",
    "        :return: Softmax activations or class predictions, depending on probs parameter.\n",
    "        \"\"\"\n",
    "        if aug1:\n",
    "            x = np.append(x, np.ones((x.shape[0], 1)), 1)\n",
    "        y = np.dot(x,self.W)#+self.b\n",
    "        # print(y)\n",
    "        if probs:\n",
    "            return np.apply_along_axis(self.softmax, 1, y)\n",
    "        else:\n",
    "            return np.argmax(np.apply_along_axis(self.softmax, 1, y), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method for calculating Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(y, y_hat):\n",
    "    \"\"\"\n",
    "    Calculates accuracy of prediction\n",
    "    :param y: true labels\n",
    "    :param y_hat: predicted labels\n",
    "    :return: accuracy in the range [0,1]\n",
    "    \"\"\"\n",
    "    return np.sum(1 * (y==y_hat))/y_hat.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n",
      "Initial Accuracy = 0.08083333333333333\n",
      "Accuracy after Iteration 1 = 0.7688166666666667\n",
      "Accuracy after Iteration 2 = 0.83065\n",
      "Accuracy after Iteration 3 = 0.8872166666666667\n",
      "Accuracy after Iteration 4 = 0.8853\n",
      "Accuracy after Iteration 5 = 0.8931\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    train_dataset = dsets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_dataset = dsets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "    train_x = train_dataset.train_data.numpy()\n",
    "    train_y = train_dataset.train_labels.numpy()\n",
    "\n",
    "    test_x = test_dataset.test_data.numpy()\n",
    "    test_y = test_dataset.test_labels.numpy()\n",
    "\n",
    "    print(train_x.shape, test_x.shape)\n",
    "\n",
    "    train_x = np.reshape(train_x, (train_x.shape[0],-1))\n",
    "    test_x = np.reshape(test_x, (test_x.shape[0],-1))\n",
    "\n",
    "    train_x = (train_x-np.mean(train_x,0))/(np.std(train_x,0)+0.00001)\n",
    "    train_one_hot_targets = np.eye(max(train_y)+1)[np.reshape(train_y,-1)]\n",
    "\n",
    "    test_x = (test_x - np.mean(test_x, 0)) / (np.std(test_x, 0) + 0.00001)\n",
    "    test_one_hot_targets = np.eye(max(test_y) + 1)[np.reshape(test_y, -1)]\n",
    "\n",
    "    #print(train_x.shape, train_y.shape)\n",
    "\n",
    "    model = SoftmaxRegression(train_x.shape[1], train_one_hot_targets.shape[1])\n",
    "\n",
    "    model.fit(train_x, train_one_hot_targets, iters=5, batch_size=20)\n",
    "\n",
    "    with open(\"SRmodel.pkl\", 'wb') as f:\n",
    "        pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Acc.\n",
      "0.8931\n",
      "Final Test Acc\n",
      "0.8866\n"
     ]
    }
   ],
   "source": [
    "    # Uncomment to load model\n",
    "    #with open(\"SRmodel.pkl\", 'rb') as f:\n",
    "    #    model = pickle.load(f)\n",
    "    \n",
    "    print(\"Final Train Acc.\")\n",
    "    preds = model.predict(train_x, False)\n",
    "    print(calculate_acc(train_y, preds))\n",
    "\n",
    "    print(\"Final Test Acc\")\n",
    "    preds = model.predict(test_x, False)\n",
    "    print(calculate_acc(test_y, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
